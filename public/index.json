[{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":null,"content":"Most of the nodes in the diagram below are clickable, which will take you to another page with much more detail on that specific issue. If you\u0026rsquo;re accessing this on an android mobile device, the flowcharts are going to look a little odd (probably huge). This is a known issue in rendering these types of diagrams. See this closed issue on GitHub and these unanswered posts on StackOverflow. If anyone has any suggestions for how to have this render on an android mobile browser, please let me know. Otherwise, good luck!\ngraph TD; linkStyle default interpolate basis A([\"How big is\nthe problem?\"]) -- |\"it's big\"| B1[(\"Don't give up yet!\")] A -- |\"no biggie\"| B2([\"Proceed with caution\"]) B1 -- C1([\"Impose assumptions\"]) B1 -- C2([\"Bounded effects\"]) click A \"/endog/problem\" \"Pre-testing\"  ","date":1597968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597968000,"objectID":"04010ed25156a7e6b5cba2734d76cfd9","permalink":"/endog/flowchart/","publishdate":"2020-08-21T00:00:00Z","relpermalink":"/endog/flowchart/","section":"endog","summary":"Most of the nodes in the diagram below are clickable, which will take you to another page with much more detail on that specific issue. If you\u0026rsquo;re accessing this on an android mobile device, the flowcharts are going to look a little odd (probably huge).","tags":null,"title":"Endogeneity Flowchart","type":"endog"},{"authors":null,"categories":null,"content":"  There’s no special formula here. Ideally, you have a strong first-stage, even after considering critical values that can accommdate “weak” instruments. If you have an overidentified model, then hopefully you can fail to reject the null of exogeneity with the Sargan or Hansen’s J test. And in such a model, hopefully you can also fail to reject the null that a subset of additional instruments have zero direct effect on your outcome, thereby supporting the excludability assumption.\nBut in reality, we are often confronted with a difficult mix of results. You may have strong evidence of a first stage for some instruments but not for all of them. In that case, Angrist and Pischke (2009) recommend that you take your best instruments and pursue a just-identified model. In such a model, you no longer have any tests for exogeneity, and your only test for exclubility is the “zero-first-stage” test on a subset of observations for which the first stage is assumed to be 0. If you have sufficiently strong instruments and a solid argument for excludability/exogeneity (hopefully with some empirical evidence to support your argument), then you can proceed to some sensitivity analyses in Step 2.\nIf you appear to have relatively strong instruments but are concerned about the exogeneity or excludability assumptions, then you may consider alternative estimation strategies that allow for some amount of violation of those assumptions. You may instead have some evidence of weak instruments, in which case you can consider alternative estimators that are robust to weak instruments (perhaps a good idea regardless, as a sensitivity analysis). Ultimately, if you have good evidence that your instruments are either 1) strong or 2) exogenous and excludable, then it’s possible to push forward with estimators that are robust to other violations. If you’re in this boat, you can move to Step 1B.\nBut if you have weak instruments that also don’t satisfy the exogeneity or excludability assumptions, then you may need to go back to the drawing board. In such a world, IV is likely to introduce more problems than it solves. If you’re in this latter situation, all is still not lost. You might be able to say something interesting, either with assumptions on the error terms as in Millimet and Tchernis (2013) or with a more agnostic bounding approach as in Manski and Pepper (2000), Kreider and Pepper (2007), Kreider et al. (2012), and Gundersen, Kreider, and Pepper (2012), among others.\nReferences Angrist, J., and J. Pischke. 2009. Mostly Harmless Econometrics. Princeton, NJ: Princeton University Press.\n Gundersen, Craig, Brent Kreider, and John Pepper. 2012. “The Impact of the National School Lunch Program on Child Health: A Nonparametric Bounds Analysis.” Journal of Econometrics 166 (1): 79–91.\n Kreider, Brent, and John Pepper. 2007. “Disability and Employment: Re-Evaluating the Evidence in Light of Reporting Errors.” Journal of the American Statistical Association 102: 432–41.\n Kreider, Brent, John Pepper, Craig Gundersen, and Dean Jolliffe. 2012. “Identifying the Effects of Snap (Food Stamps) on Child Health Outcomes When Participation Is Endogenous and Misreported.” Journal of the American Statistical Association 107: 958–75.\n Manski, Charles, and John Pepper. 2000. “Monotone Instrumental Variables: With an Application to the Returns to Schooling.” Econometrica 68: 997–1010.\n Millimet, Daniel L, and Rusty Tchernis. 2013. “Estimation of Treatment Effects Without an Exclusion Restriction: With an Application to the Analysis of the School Breakfast Program.” Journal of Applied Econometrics 28: 982–1017.\n   ","date":1597104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597104000,"objectID":"b9af1e1fa9217ccb0f51c761935564a1","permalink":"/iv/step1_assess/","publishdate":"2020-08-11T00:00:00Z","relpermalink":"/iv/step1_assess/","section":"iv","summary":"There’s no special formula here. Ideally, you have a strong first-stage, even after considering critical values that can accommdate “weak” instruments. If you have an overidentified model, then hopefully you can fail to reject the null of exogeneity with the Sargan or Hansen’s J test.","tags":null,"title":"Assessing your instruments","type":"iv"},{"authors":null,"categories":null,"content":"   “The best laid plans of mice and men often go awry”\n No matter how great you think your instrument is, your data may say otherwise. Maybe your “zero-first-stage” test fails, or maybe you have an overidentified model and you reject your Sargan or Hansen’s \\(J\\) test. Whatever the reason, you’re here because you’re starting to suspect that your instruments aren’t all you’d hoped.\nLet’s assume that you still have a strong first stage. If not, then you may need another estimation strategy altogether.\n","date":1597104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597104000,"objectID":"443b5ca3feea039ef23c71a5d2f70746","permalink":"/iv/step1b_exog_excl/","publishdate":"2020-08-11T00:00:00Z","relpermalink":"/iv/step1b_exog_excl/","section":"iv","summary":"“The best laid plans of mice and men often go awry”\n No matter how great you think your instrument is, your data may say otherwise. Maybe your “zero-first-stage” test fails, or maybe you have an overidentified model and you reject your Sargan or Hansen’s \\(J\\) test.","tags":null,"title":"Invalid Instruments","type":"iv"},{"authors":null,"categories":null,"content":"  If you’re here, it means you’re uncomfortable with some of the required IV assumptions. Either you have some statistical evidence that your assumptions may not hold, or you suspect some violation of assumptions that you can’t test (e.g., the exogeneity assumption in a just-identified model). Or maybe you think everything is great but a reviewer thinks otherwise.\nEither way, the goal now is to consider treatment effect estimates that are robust to violations of some of the key IV assumptions. Click on the links below for more detail:\nFirst stage: Weak instruments\n Exogeneity/Excludability: Instruments are also endogenous or directly affect the outcome\n  ","date":1597104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597104000,"objectID":"73de64152b2357dfe1125757b3df276e","permalink":"/iv/step1b_overall/","publishdate":"2020-08-11T00:00:00Z","relpermalink":"/iv/step1b_overall/","section":"iv","summary":"If you’re here, it means you’re uncomfortable with some of the required IV assumptions. Either you have some statistical evidence that your assumptions may not hold, or you suspect some violation of assumptions that you can’t test (e.","tags":null,"title":"Some violations...","type":"iv"},{"authors":null,"categories":null,"content":"  What do we do if we have weak instruments?\nI guess one option is to go look for better instruments, but I’m going to assume you’ve already identified your best potential instruments.\nWeak IV robust inference Let’s assume we have our usual equation of interest, \\[y = x_{1} \\beta_{1} + x_{2} \\beta_{2} + \\varepsilon,\\] where \\(x_{1}\\) is assumed to be endogenous and \\(x_{2}\\) exogenous. We have some instruments, \\(z\\), that are correlated with \\(x_{1}\\). But, we’re concerned that this correlation may be relatively low. Regardless, the coefficient of interest is still \\(\\beta_{1}\\), and so one approach to dealing with weak IVs is to develop a test of \\(H_{0}: \\beta_{1}=0\\) that is robust to weak instruments.\nOne approach to this is the Anderson-Rubin test (Anderson, Rubin, and others 1949). This is a test of \\(H_{0}: \\gamma_{1} = 0\\) in the “reduced-form”, \\[y = z \\gamma_{1} + x_{2} \\gamma_{2} + \\nu.\\] If we reject this test (i.e., there is evidence that \\(\\gamma_{1} \\neq 0\\)) then it is also evidence that \\(\\beta_{1} \\neq 0\\). That’s because, with weak instruments, the coefficient on \\(z\\) in the first stage regression of \\(x_{1}\\) on \\(z\\) and \\(x_{2}\\) is close to 0 and would tend to decrease the probability of rejecting the null of \\(\\gamma_{1}=0\\).\nChernozhukov and Hansen (2008) extends this approach by constructing a confidence interval for \\(\\beta_{1}\\) that is robust to weak instruments. Using our current notation, they propose the following process:\nPick a value, \\(b\\), for \\(\\beta_{1}\\). Construct \\(\\tilde{y} = y - x_{1} b\\) and regress \\(\\tilde{y}\\) on \\(z\\) and \\(x_{2}\\). Calculate the Wald statistic for \\(b\\), \\(W(b) = \\hat{\\gamma}\u0026#39; Var(\\hat{\\gamma})^{-1} \\hat{\\gamma} \\sim \\chi ^{2}_{r}\\). Construct the confidence region as the set of \\(b\\) such that \\(W_{s}(b) \\leq c(1-p)\\), where \\(c(1-p)\\) is the \\((1-p)^{th}\\) percentile of the \\(\\chi^{2}_{r}\\) distribution (\\(r\\) is the number of instruments).   Two-step robust inference One issue with the above approach is that we are really considering a two-stage process. In stage 1, we assess the general strength of the instrument, and in stage 2, if we’ve identified evidence of a weak instrument, then we pursue some form of weak IV robust inference. But failure to account for the first stage in our second stage confidence intervals could lead to some problems, such that we may incorrectly reject the null. This is where some recent methods in Finlay and Magnusson (2009) and Andrews (2018) can help in developing confidence intervals that appropriately account for the first-stage of this process. Commands to estimate such confidence intervals are available in Stata with weakiv and twostepweakiv, respectively.\nThe result of these intervals, for the purposes of weak IV robust inference, is a range of values \\(b\\) such that the null \\(H_{0}: \\beta_{1}=b\\) cannot be rejected (at the given significance level used to construct the interval).\n References Anderson, Theodore W, Herman Rubin, and others. 1949. “Estimation of the Parameters of a Single Equation in a Complete System of Stochastic Equations.” The Annals of Mathematical Statistics 20 (1): 46–63.\n Andrews, Isaiah. 2018. “Valid Two-Step Identification-Robust Confidence Sets for Gmm.” Review of Economics and Statistics 100 (2): 337–48.\n Chernozhukov, Victor, and Christian Hansen. 2008. “The Reduced Form: A Simple Approach to Inference with Weak Instruments.” Economics Letters 100 (1): 68–71.\n Finlay, Keith, and Leandro M Magnusson. 2009. “Implementing Weak-Instrument Robust Tests for a General Class of Instrumental-Variables Models.” The Stata Journal 9 (3): 398–421.\n   ","date":1597104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597104000,"objectID":"5cde019224fc5bcf624453f1124636c8","permalink":"/iv/step1b_firststage/","publishdate":"2020-08-11T00:00:00Z","relpermalink":"/iv/step1b_firststage/","section":"iv","summary":"What do we do if we have weak instruments?\nI guess one option is to go look for better instruments, but I’m going to assume you’ve already identified your best potential instruments.","tags":null,"title":"Weak Instruments","type":"iv"},{"authors":null,"categories":null,"content":"  Unfortunately, this is again an area where I’ve already oversold the topic. In general, we can’t test for instrument exogeneity. It’s just one of those assumptions that we have to maintain if we’re going to use IV.\nBut all is not lost. We can (somewhat) test this assumption if we have more instruments than we do endogenous variables (i.e., if we have an overidentified model). With homoskedastic errors, we run a Sargan test, and with heteroskedastic errors, we use the Hansen’s J test (Sargan 1958, @hansen1982). Each test is readily available in Stata’s ivreg command. For R users, The Sargan test is part of ivreg diagnostics, but the Hansen’s J test isn’t immediately available without employing other estimators from other packages. So R users have to do a little bit more work, or you can use the RStata package and run Stata code in R.\nFinally, note that the null in each test is that your instruments are exogenous. Rejecting the null therefore suggests we might have a problem. But failing to reject the null doesn’t necessarily mean exogeneity holds. So, there’s that.\nReferences Hansen, Lars Peter. 1982. “Large Sample Properties of Generalized Method of Moments Estimators.” Econometrica: Journal of the Econometric Society, 1029–54.\n Sargan, John D. 1958. “The Estimation of Economic Relationships Using Instrumental Variables.” Econometrica: Journal of the Econometric Society, 393–415.\n   ","date":1596758400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596758400,"objectID":"cd59d3b6fe1bf438f506a0d3b38e8a7f","permalink":"/iv/step1_exog/","publishdate":"2020-08-07T00:00:00Z","relpermalink":"/iv/step1_exog/","section":"iv","summary":"Unfortunately, this is again an area where I’ve already oversold the topic. In general, we can’t test for instrument exogeneity. It’s just one of those assumptions that we have to maintain if we’re going to use IV.","tags":null,"title":"Testing for Exogeneity","type":"iv"},{"authors":null,"categories":null,"content":"  The exclusion restriction says that your instruments do not directly affect your outcome, so that it is appropriately “excluded” from the main equation of interest. This assumption goes by different names and is sometimes combined with other IV assumptions. For example, sometimes you see this assumption lumped into the first stage requirement and stated as an “only-through” assumption (i.e., the instrument affects the outcome only through the endogenous variable of interest).\nRegardless, the exclusion restriction is hard to test because the instrument should also be correlated with the endogenous variable of interest. Isolating variation coming only from the instrument, separately from any variation coming from the instrument via the endogenous variable, is not feasible in a general setting.\nBut don’t lose all hope yet. There are a couple of things we can do. One initial test is what Kippersluis and Rietveld (2018) refers to as a “zero-first-stage” test. The idea is that you have a subsample for which your instrument is not correlated with the endogenous variable of interest. You then regress the outcome on all covariates and the instruments, among the subsample for which there is no first stage effect. The resulting coefficient on the instruments then captures any potential direct effect of the instruments on the outcome (since the correlation with the endogenous variable is 0 by assumption).\nYou can go a little further with this, as shown in Altonji, Elder, and Taber (2005), and use this approach to directly estimate the extent of the bias from violations of the exclusion restriction. However, a more recent approach to deal with violations of the exclusion restriction is in Conley, Hansen, and Rossi (2012) and Kippersluis and Rietveld (2018), which I discuss in more detail in Step 1B: Violations of the exclusion restriction.\nIf you have an overidentified model, then you can test the exclusion restriction alongside the exogeneity assumption for a subset of instruments (Beckert 2020). Paraphrasing Beckert (2020), assuming we have \\(m\\) instruments and \\(n\\) endogenous variables, then under the maintained assumption that there are at least \\(n\\) valid instruments, you can test the null that all instruments are valid against the alternative that up to \\(m - n\\) instruments are valid.\nWe can implement this test easily. First, we estimate the first-stage regressions (regression of our endogenous variables on the instruments and all other exogenous variables). Second, we save the residuals from these regressions, denoted \\(\\hat{u}\\). Third, we estimate the “artificial” regression \\[y = \\beta x + \\delta \\tilde{z} + \\gamma \\hat{u} + \\varepsilon,\\] where \\(\\tilde{z}\\) denotes a subset of \\(m-n\\) instruments from the full instrument matrix \\(z\\). We then test the null that \\(\\delta=0\\) using a standard F-test.\nReferences Altonji, Joseph G, Todd E Elder, and Christopher R Taber. 2005. “An Evaluation of Instrumental Variable Strategies for Estimating the Effects of Catholic Schooling.” Journal of Human Resources 40 (4): 791–821.\n Beckert, Walter. 2020. “A Note on Specification Testing in Some Structural Regression Models.” Oxford Bulletin of Economics and Statistics 82 (3): 686–95.\n Conley, Timothy G, Christian B Hansen, and Peter E Rossi. 2012. “Plausibly Exogenous.” Review of Economics and Statistics 94 (1): 260–72.\n Kippersluis, Hans van, and Cornelius A Rietveld. 2018. “Beyond Plausibly Exogenous.” The Econometrics Journal 21 (3): 316–31.\n   ","date":1596758400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596758400,"objectID":"e465367a55547e171c83208a0c4d9fbb","permalink":"/iv/step1_exclude/","publishdate":"2020-08-07T00:00:00Z","relpermalink":"/iv/step1_exclude/","section":"iv","summary":"The exclusion restriction says that your instruments do not directly affect your outcome, so that it is appropriately “excluded” from the main equation of interest. This assumption goes by different names and is sometimes combined with other IV assumptions.","tags":null,"title":"Testing the Exclusion Restriction","type":"iv"},{"authors":null,"categories":null,"content":"  If you’ve made it this far, then you are confident that you have some real endogeneity problems and that IV is at least a possibility. Before going any further, we have to put your instruments to the test. Cue the montage.\nThis stage is all about testing the three key assumptions to any IV. Click on the links below to go to more detail on each assumption, or go back to the flowchart.\nFirst stage: Our instrument must be correlated with the endogenous variable of interest.\n Exogeneity: Our instrument must be exogenous.\n Excludability: The instrument must be correlated with the outcome, but only through the endogenous variable.\n  ","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"f6b59027b6e7b78a19f519ee557d224d","permalink":"/iv/step1_overall/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/iv/step1_overall/","section":"iv","summary":"If you’ve made it this far, then you are confident that you have some real endogeneity problems and that IV is at least a possibility. Before going any further, we have to put your instruments to the test.","tags":null,"title":"Are your instruments any good?","type":"iv"},{"authors":null,"categories":null,"content":"  It would be great if we could test for whether we really had an endogeneity problem or not. But alas, that’s just not in the cards. Instead, a good starting point is just to see “how much” of endogeneity problem we’d have to have to overturn our current results.\nCoefficient Stability Oster (2019) can help us here. Here’s the idea…\nLots of applied researchers assess “coefficient stability” by including different sets of control variables that are intended to proxy for some potentially important unobserved factor. This is not informative of omitted variables bias if the existing controls already do a very poor job of explaining the outcome. As Prof. Oster notes, “Omitted variable bias is proportional to coefficient movements, but only if such movements are scaled by the change in R-squared when controls are included.”\nExtending the work of Altonji, Elder, and Taber (2005), Oster (2019) lays out a scenario in which we can fully decompose our outcome of interest into a treatment effect (denoted \\(\\beta\\)), observed controls (denoted by \\(W_{1}\\)), unobserved controls (denoted by \\(W_{2}\\)), and some iid error term. Denote by \\(X\\) the treatment variable, such that \\[Y = \\beta X + W_{1} + W_{2} + \\epsilon.\\] We then need to consider values (or a range of values) for two key objects.\nWhat is the maximum \\(R^2\\) value we could obtain if we observed \\(W_{2}\\)? Let’s call this \\(R_{\\text{max}}^{2}\\). If we think the outcome is fully deterministic if we were to observe all relevant variables, then \\(R_{\\text{max}}^{2}=1\\), but we could consider smaller values as well.\n What is the degree of selection on observed variables relative to unobserved variables? We can denote this value as \\(\\delta\\), and define \\(\\delta\\) as the value such that: \\[\\delta \\times \\frac{Cov(W_{1},X)}{Var(W_{1})} = \\frac{Cov(W_{2},X)}{Var(W_{2})}.\\]\n  We then need to define a few objects that we can directly estimate with the data:\nDenote by \\(R^{2}_{X}\\) the \\(R^{2}\\) from a regression of \\(Y\\) on treatment (and only treatment, no covariates). Similarly denote by \\(\\hat{\\beta}_{X}\\) the value of \\(\\beta\\) estimated from that regression.\n Denote by \\(R^{2}_{X,W_{1}}\\) the \\(R^{2}\\) from a regression of \\(Y\\) on treatment and observed controls. Again, denote the estimated value of \\(\\beta\\) from this regression as \\(\\hat{\\beta}_{X, W_{1}}\\).\n  Under the assumption that the relative size of coefficients from a regression of \\(Y\\) on \\(X\\) and observed variables are equal to those from a regression of \\(X\\) and the observed variables, Oster (2019) then shows that the true coefficient of interest (\\(\\beta\\) from the full regression) converges to the following:\n\\[\\beta^{*} \\approx \\hat{\\beta}_{X,W_{1}} - \\delta \\times \\left[\\hat{\\beta}_{X} - \\hat{\\beta}_{X,W_{1}}\\right] \\times \\frac{R_{max}^{2} - R_{X,W_{1}}^{2}}{R_{X,W_{1}}^{2} - R_{X}^{2}} \\xrightarrow{p} \\beta.\\]\nIf we relax the assumption of equal “relative contributions” between the observed covariates and \\(Y\\) versus the observed covariates and \\(X\\), then the results are a little more complicated. In that case, Oster (2019) shows that \\[\\beta^{*} = \\hat{\\beta}_{X,W_{1}} - \\nu_{1} \\xrightarrow{p} \\beta,\\] or \\[\\beta^{*} \\in \\left\\{ \\hat{\\beta}_{X,W_{1}} - \\nu_{1}, \\hat{\\beta}_{X,W_{1}} - \\nu_{2}, \\hat{\\beta}_{X,W_{1}} - \\nu_{3} \\right\\},\\] where \\(\\nu_{1}\\), \\(\\nu_{2}\\), and \\(\\nu_{3}\\) are roots of a cubic function, \\(f(\\nu)\\), derived in the paper. In the case of more than one root, then one element of \\(\\beta^{*}\\) converges in probability to \\(\\beta\\). If \\(\\delta=1\\), then some additional simplifications can be made, but the point is that we now have an expression for the bias as a function of \\(\\delta\\) and \\(R^{2}_{max}\\).\nSo what do we gain from all of this? Well, Oster (2019) shows that we can also work backwards and find the value of \\(\\delta\\) such that \\(\\beta=0\\). In other words, say we estimate using OLS some effect, \\(\\hat{\\beta}_{X, W_{1}}\\). How big must the role of selection on unobservables be in order to completely overpower our estimate such that the true effect is actually 0?\nAnother approach is to consider a range of \\(R^{2}_{max}\\) and \\(\\delta\\) to bound the estimated treatment effect. Using \\(\\delta=1\\) as an upper bound for \\(\\delta\\) (i.e., observables are at least as important as the unobservables), and \\(\\bar{R}^{2}_{max}\\) as an upper bound for \\(R^{2}_{max}\\), then the bounds on \\(\\beta^{*}\\) are \\(\\left[ \\hat{\\beta}_{X,W_{1}}, \\beta^{*}(\\bar{R}^{2}_{max}, 1) \\right]\\).\nFinally, Oster (2019) suggests setting \\(\\delta=1\\) and identifying the value of \\(R^{2}_{max}\\) for which \\(\\beta=0\\). This would tell us how much of the variation in \\(Y\\) would need to be explained by unobservables in order for the true effect to be null (given our estimate, \\(\\hat{\\beta}_{X,W_{1}}\\).\nThere is also a Stata command, psacalc, to do these calculations for us!\n# References\nAltonji, Joseph G, Todd E Elder, and Christopher R Taber. 2005. “An Evaluation of Instrumental Variable Strategies for Estimating the Effects of Catholic Schooling.” Journal of Human Resources 40 (4): 791–821.\n Oster, Emily. 2019. “Unobservable Selection and Coefficient Stability: Theory and Evidence.” Journal of Business \u0026amp; Economic Statistics 37 (2): 187–204. https://doi.org/10.1080/07350015.2016.1227711.\n   ","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"c950b924db844f9d0ad739441bcb9c76","permalink":"/endog/problem/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/endog/problem/","section":"endog","summary":"It would be great if we could test for whether we really had an endogeneity problem or not. But alas, that’s just not in the cards. Instead, a good starting point is just to see “how much” of endogeneity problem we’d have to have to overturn our current results.","tags":null,"title":"How big is the problem?","type":"endog"},{"authors":null,"categories":null,"content":"  It would be great if we could test for whether we need IV or not. But unfortunately, I’ve already oversold this section. There is no magic “test” for whether you need IV.\nBut all is not lost. Even though we can’t definitively say that we need to use IV we can at least see different some IV results might be relative to OLS (assuming we have some decent instruments already).\nIV vs OLS An easy way to assess the need for IV is to simply test whether your IV results are sufficiently different from OLS. That’s the spirit of the Hausman test. The original test introduced in Hausman (1978) is not specific to endogeneity…it’s a more general misspecification test, comparing the estimates from one estimator (that is efficient under the null) to that of another estimator that is consistent but inefficient under the null. The test in the context of IV is also referred to as the Durbin-Wu-Hausman test, due to the series of papers pre-dating Hausman (1978), including Durbin (1954), Wu (1973), and Wu (1974).\nThis test is easily implemented as an “artificial” or “augmented” regression. Denoting our outcome by \\(y\\), our instruments by \\(z\\), our endogeous variables by \\(x_{1}\\), and other exogenous variables by \\(x_{2}\\), we first regress each of the variables in \\(x_{1}\\) on \\(x_{2}\\) and \\(z\\). Then we take the residuals from those regressions, denoted \\(\\hat{v}\\), and include them in the standard OLS regression of \\(y\\) on \\(x_{1}\\), \\(x_{2}\\), and \\(\\hat{v}\\).\nThe biggest barrier to this test in practice is that it assumes we have a valid and strong set of instruments, \\(z\\). Since that’s usually the biggest barrier to causal inference with IV, it becomes a major practical problem. For example, if you reject the null and conclude that estimates from OLS and IV are statistically different, can you be sure that the difference is “real” and not a statistical artifact of weak or invalid instruments? The whole process becomes pretty circular.\n References Durbin, James. 1954. “Errors in Variables.” Revue de L’institut International de Statistique, 23–32.\n Hausman, Jerry A. 1978. “Specification Tests in Econometrics.” Econometrica: Journal of the Econometric Society, 1251–71.\n Wu, De-Min. 1973. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances.” Econometrica: Journal of the Econometric Society, 733–50.\n ———. 1974. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances: Finite Sample Results.” Econometrica: Journal of the Econometric Society, 529–46.\n   ","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"dd92715559e69b383db036dc63d37b9f","permalink":"/iv/problem/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/iv/problem/","section":"iv","summary":"It would be great if we could test for whether we need IV or not. But unfortunately, I’ve already oversold this section. There is no magic “test” for whether you need IV.","tags":null,"title":"How big is the problem?","type":"iv"},{"authors":null,"categories":null,"content":"  The “first stage” is just a common term for a regression of the endogenous variable, \\(x\\), on your instrument, \\(z\\) (and any other exogenous variables). If you have more than one endogeous variable, then you will have more than one first stage, but all of your instruments should be in each of those regressions. The intuition is simple, if you have a proposed instrument, it should at least be correlated with your endogenous variable of interest (after conditioning on all other exogenous variables already in the model). As with lots of econometrics, this sounds simple until it’s not. To preview some of this complexity, I’m only focusing on linear IV models here…the literature on non-linear IV models is less developed as far as I can tell.\nUnderidentification versus weak instruments It is easy to confuse the question of underidentification versus weak instruments, but they are different issues. In the case of underidentification, we are explicitly interested in testing whether the partial correlation between the instrument(s) and the endogenous variable(s) is 0. In other words, is the instrument matrix of full rank? But it is possible to reject the null that the instruments and endogenous variables are uncorrelated, while still have very weak instruments. The literature therefore distinguishes between tests of 0 correlation versus tests that are robust to weak instruments (e.g., a test for which rejection of the null suggests that the instruments are sufficiently “strong”). Luckily, this distinction relates to the critical value to which you compare a given test statistic. In other words, a test of underidentification can use standard critical values, while a test allowing for weak instruments will tend to require slightly higher critical values (harder to reject).\n One endogenous variable This is the simplest possible setup, and one in which you essentially focus on the significance (or, in the case of more than one instrument, joint significance) of your instruments in a regression of \\(x\\) on \\(z\\) and all other exogenous variables. A standard t-test or F-test using traditional critical values would be a test of underidentification.\nAs is well-known, an F-stat of 10 is considered a decent rule-of-thumb for testing the first stage. This value was first proposed in Staiger and Stock (1997), and it’s important because it’s larger than the standard critical values. The reason it’s larger is because the Staiger and Stock (1997) critical values allow for weak instruments. While the rule-of-thumb value of 10 is common and useful, the literature has probably taken this threshold a little too seriously (see Figure 1 in Andrews, Stock, and Sun (2019), which shows a big spike at 10 in the empirical distribution of reported F-stats among papers published in the AER).\nAnother popular first-stage assessment is the partial \\(R^{2}\\), sometimes called Shea’s Partial \\(R^{2}\\) (Shea 1997). This is the \\(R^{2}\\) of a regression of our endogenous variable on the instruments after partialling out the other exogenous variables. In other words, we regress our endogenous variable on our instrument(s), and we regress each of the exogenous covariates on our instrument(s). We then take the residual from each of those regressions and run another regression of the residualized endogenous variable against the residualized instruments. The \\(R^{2}\\) of that regression is the partial \\(R^{2}\\) because the influence of the the other exogenous variables has been removed. If the partial \\(R^{2}\\) is “low”, then we should suspect that our instruments are weak. The problem is that there is no clear value for “low” or “high”, and the distribution of this statistic is nonstandard. I suspect that, for this reason, Shea’s Partial \\(R^{2}\\) is not a commonly-reported measure of instrument strength in most published work.\nFinally, Olea and Pflueger (2013) propose an “effective” F-stat that allows for heteroskedasticity. This hasn’t received much attention in the applied literature, but Andrews, Stock, and Sun (2019) encourages wider adoption of such a test. You can implement this in Stata with weakivtest. The effective F-stat is equivalent to a robust F-stat (i.e., the usual first-stage F-stat using robust standard errors) in the case of a single instrument. But with multiple instruments and one endogenous variable, the effective F-stat looks to be the best option for assessing the strength of your instruments.\n Multiple endogenous variables With more than one endogenous variable, Stock and Yogo (2005) develops critical values based on the Cragg-Donald statistic (Cragg and Donald 1993). A statistic similar to Cragg-Donald is the Anderson LM statistic, both of which are readily reported in Stata’s ivreg2 command. Unfortunately, both statistics require the assumption of homoskedastic errors. Shea’s Partial \\(R^{2}\\) also isn’t particularly informative in the case of multiple endogenous variables, again a potential reason for its limited use in practice.\nIn the more realistic heteroskedastic setting, the appropriate tests are more complicated. The Kleibergen-Paap rank-based (rk) statistic can be used to implement a Lagrange-Multiplier (LM) test that is a robust version of the Cragg-Donald statistic (Kleibergen and Paap 2006); however, the Kleibergen-Paap LM test is purely an “underidentification” test, and it is possible to reject the null while still having very weak correlation between your instruments and endogenous variables. For inference that is robust to weak instruments and heteroskedasticity, we can employ the Kleibergen-Paap rk Wald test with the critical values from Stock and Yogo (2005). This is the approach recommended in Baum, Schaffer, and Stillman (2007), although this approach is not formalized. The Kleibergen-Paap rk Wald statistics is also only recommended for just-identified models.\nNote that the Cragg-Donald statistic or the Kleibergen-Paap rk statistic each provide a single test statistic for all of the instruments and all of the endogenous variables. But what if you have more than one endogenous variable and just one of the IVs is predominatly driving the identification in all cases? In that case, it can be good to look at tests separately for each endogenous variable. Angrist and Pischke (2009) and Sanderson and Windmeijer (2016) provide such an approach.\nUltimately, if you have more than one endogenous variables and the same number of instruments, then the Kleibergen-Paap rk Wald test with critical values from Stock and Yogo (2005) (or at least the rule-of-thumb critical value of 10) is the best option with heteroskedastic or clustered errors. I have not yet seen any tests for an overidentified model with more than one endogenous variable and heteroskedasticity. If you have such a model but feel strongly about including all of the instruments, then one approach would be to consider as a sensitivity analysis the just-identified version of your model with your subset of “best” instruments.\n References Andrews, Isaiah, James H Stock, and Liyang Sun. 2019. “Weak Instruments in Instrumental Variables Regression: Theory and Practice.” Annual Review of Economics 11: 727–53.\n Angrist, J., and J. Pischke. 2009. Mostly Harmless Econometrics. Princeton, NJ: Princeton University Press.\n Baum, Christopher F, Mark E Schaffer, and Steven Stillman. 2007. “Enhanced Routines for Instrumental Variables/Generalized Method of Moments Estimation and Testing.” The Stata Journal 7 (4): 465–506.\n Cragg, John G, and Stephen G Donald. 1993. “Testing Identifiability and Specification in Instrumental Variable Models.” Econometric Theory, 222–40.\n Kleibergen, Frank, and Richard Paap. 2006. “Generalized Reduced Rank Tests Using the Singular Value Decomposition.” Journal of Econometrics 133 (1): 97–126.\n Olea, José Luis Montiel, and Carolin Pflueger. 2013. “A Robust Test for Weak Instruments.” Journal of Business \u0026amp; Economic Statistics 31 (3): 358–69.\n Sanderson, Eleanor, and Frank Windmeijer. 2016. “A Weak Instrument F-Test in Linear Iv Models with Multiple Endogenous Variables.” Journal of Econometrics 190 (2): 212–21.\n Shea, John. 1997. “Instrument Relevance in Multivariate Linear Models: A Simple Measure.” The Review of Economics and Statistics 79 (2): 348–52.\n Staiger, Douglas, and James H Stock. 1997. “Instrumental Variables Regression with Weak Instruments.” Econometrica 65 (3): 557–86.\n Stock, James H, and Motohiro Yogo. 2005. “Testing for Weak Instruments in Linear Iv Regression.” In Identification and Inference for Econometric Models: Essays in Honor of Thomas Rothenberg. Cambridge University Press.\n   ","date":1596412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596412800,"objectID":"a6e10ef08a6c5f867bfd0fc8dc167b0f","permalink":"/iv/step1_firststage/","publishdate":"2020-08-03T00:00:00Z","relpermalink":"/iv/step1_firststage/","section":"iv","summary":"The “first stage” is just a common term for a regression of the endogenous variable, \\(x\\), on your instrument, \\(z\\) (and any other exogenous variables). If you have more than one endogeous variable, then you will have more than one first stage, but all of your instruments should be in each of those regressions.","tags":null,"title":"Testing the First Stage","type":"iv"},{"authors":null,"categories":null,"content":"Most of the nodes in the diagram below are clickable, which will take you to another page with much more detail on that specific issue. In practice, empirical work is not so linear, and there is typically a lot of recirculation among these steps. For example, you may have 2 endogenous variables and 4 instruments. You may find that 1 or 2 of those instruments are weak, and as you learn this information, you are constantly recirculating in stage 1. You may settle on 3 instruments that seem to work well. Then, in Stage 2, you may find that your results are very sensitive with those instruments, but less sensitive when relying on only 2 of those 3 instruments. So now you go back to step 1, evaluate just those 2 instruments, etc.\nThe point is that empirical work in practice is messy. Ideally, we could set out our plan in advance and proceed accordingly, but there are some things we just can\u0026rsquo;t know until we see the data. All we can do is work through the process in good faith, assessing the quality of our empirical work based on sound statistics and econometrics.\nOne final note. If you\u0026rsquo;re accessing this on an android mobile device, the flowcharts are going to look a little odd (probably huge). This is a known issue in rendering these types of diagrams. See this closed issue on GitHub and these unanswered posts on StackOverflow. If anyone has any suggestions for how to have this render on an android mobile browser, please let me know. Otherwise, happy instrumenting!\ngraph TD; linkStyle default interpolate basis A([\"Thinking of IV?\"]) -- B([\"Does it really matter?\"]) B -- |\"yes!\"| C1([\"Are your instruments\nany good?\"]) B -- |\"I guess not\"| C2([\"Nevermind:\ntry something else\"]) subgraph one [\"Stage 1: Requirements for any IV\"] C1 -- D1([\"first-stage\"]) C1 -- D2([\"exogeneity\"]) C1 -- D3([\"exclusion\"]) D1 -- E([\"assess instruments\"]) D2 -- E D3 -- E end subgraph two [\"Stage 1b: Something is better than nothing\"] E -- |\"kind of ok\"| e1([\"Some violations\"]) e1 -- f1([\"first-stage\"]) e1 -- f2([\"exogeneity/exclusion\"]) f1 -- g([\"pick something\"]) f2 -- g end subgraph three [\"Stage 2: Still not in the clear\"] E -- |\"so far so good!\"| E1([\"How sensitive are\nthe results?\"]) g -- E1 E1 -- F1([\"IV is biased!\"]) E1 -- F2([\"what about outliers?\"]) F1 -- G([\"assess sensitivity\"]) F2 -- G end E -- |\"ouch, no bueno\"| C2 G -- |\"um, define sensitive\"| C2 G -- |\"not too bad!\"| H([\"What am I\nestimating, again?\"]) H -- |\"can I be done?\"| I([\"Go forth and write\nthat appendix!\"]) click B \"/iv/problem\" \"Pre-testing\" click C1 \"/iv/step1_overall\" \"Stage 1\" click D1 \"/iv/step1_firststage\" \"Testing the first stage\" click D2 \"/iv/step1_exog\" \"Testing the exogeneity assumption\" click D3 \"/iv/step1_exclude\" \"Testing the exclusion assumption\" click E \"/iv/step1_assess\" \"Assessing your instrument tests\" click e1 \"/iv/step1b_overall\" \"IVs are OK, but not great\" click f1 \"/iv/step1b_firststage\" \"Weak IV Robust Inference\" click f2 \"/iv/step1b_exog_excl\" \"Invalid IVs\" click C2 \"/\" \"Try something else\" click I \"https://davidcard.berkeley.edu/papers/card-dellavigna-pagelimits.pdf\" \"Page limits are non-binding.\"  ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596067200,"objectID":"81ee54c0dccddc59859ce6e78a054972","permalink":"/iv/flowchart/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/iv/flowchart/","section":"iv","summary":"Most of the nodes in the diagram below are clickable, which will take you to another page with much more detail on that specific issue. In practice, empirical work is not so linear, and there is typically a lot of recirculation among these steps.","tags":null,"title":"Instrumental Variables Flowchart","type":"iv"}]