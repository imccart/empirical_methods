<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Navigating Empirical Microeconomics</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Navigating Empirical Microeconomics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><lastBuildDate>Fri, 21 Aug 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu868eca74f8a4177df052375a5d8f7185_1119_512x512_fill_lanczos_center_2.png</url>
      <title>Navigating Empirical Microeconomics</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Example Page 1</title>
      <link>/courses/example/example1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page 2</title>
      <link>/courses/example/example2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/courses/example/example2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;tip-3&#34;&gt;Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;tip-4&#34;&gt;Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Endogeneity Flowchart</title>
      <link>/endog/flowchart/</link>
      <pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/endog/flowchart/</guid>
      <description>&lt;p&gt;Most of the nodes in the diagram below are clickable, which will take you to another page with much more detail on that specific issue. If you&amp;rsquo;re accessing this on an android mobile device, the flowcharts are going to look a little odd (probably huge). This is a known issue in rendering these types of diagrams. See this closed 
&lt;a href=&#34;https://github.com/mermaid-js/mermaid/issues/816&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;issue on GitHub&lt;/a&gt; and these unanswered 
&lt;a href=&#34;https://stackoverflow.com/search?q=%5Bmermaid%5D&amp;#43;chrome&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;posts on StackOverflow&lt;/a&gt;. If anyone has any suggestions for how to have this render on an android mobile browser, please let me know. Otherwise, good luck!&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;
graph TD;
    linkStyle default interpolate basis
    A([&#34;How big is&lt;br&gt; the problem?&#34;]) --&gt; |&#34;it&#39;s big&#34;| B1[(&#34;Don&#39;t give up yet!&#34;)]
    A --&gt; |&#34;no biggie&#34;| B2([&#34;Proceed with caution&#34;])
    B1 --&gt; C1([&#34;Impose assumptions&#34;])
    B1 --&gt; C2([&#34;Bounded effects&#34;])
    click A &#34;/endog/problem&#34; &#34;Pre-testing&#34;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Assessing your instruments</title>
      <link>/iv/step1_assess/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1_assess/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;There’s no special formula here. Ideally, you have a strong first-stage, even after considering critical values that can accommdate “weak” instruments. If you have an overidentified model, then hopefully you can fail to reject the null of exogeneity with the Sargan or Hansen’s &lt;em&gt;J&lt;/em&gt; test. And in such a model, hopefully you can also fail to reject the null that a subset of additional instruments have zero direct effect on your outcome, thereby supporting the excludability assumption.&lt;/p&gt;
&lt;p&gt;But in reality, we are often confronted with a difficult mix of results. You may have strong evidence of a first stage for some instruments but not for all of them. In that case, &lt;span class=&#34;citation&#34;&gt;Angrist and Pischke (2009)&lt;/span&gt; recommend that you take your best instruments and pursue a just-identified model. In such a model, you no longer have any tests for exogeneity, and your only test for exclubility is the “zero-first-stage” test on a subset of observations for which the first stage is assumed to be 0. If you have sufficiently strong instruments and a solid argument for excludability/exogeneity (hopefully with some empirical evidence to support your argument), then you can proceed to some sensitivity analyses in &lt;a href=&#34;/iv/step2_overall&#34;&gt;Step 2&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you appear to have relatively strong instruments but are concerned about the exogeneity or excludability assumptions, then you may consider alternative estimation strategies that allow for &lt;em&gt;some&lt;/em&gt; amount of violation of those assumptions. You may instead have some evidence of weak instruments, in which case you can consider alternative estimators that are robust to weak instruments (perhaps a good idea regardless, as a sensitivity analysis). Ultimately, if you have good evidence that your instruments are either 1) strong or 2) exogenous and excludable, then it’s possible to push forward with estimators that are robust to other violations. If you’re in this boat, you can move to &lt;a href=&#34;/iv/step1b_overall&#34;&gt;Step 1B&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But if you have weak instruments that also don’t satisfy the exogeneity or excludability assumptions, then you may need to go back to the drawing board. In such a world, IV is likely to introduce more problems than it solves. If you’re in this latter situation, all is still not lost. You might be able to say something interesting, either with assumptions on the error terms as in &lt;span class=&#34;citation&#34;&gt;Millimet and Tchernis (2013)&lt;/span&gt; or with a more agnostic bounding approach as in &lt;span class=&#34;citation&#34;&gt;Manski and Pepper (2000)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;Kreider and Pepper (2007)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;Kreider et al. (2012)&lt;/span&gt;, and &lt;span class=&#34;citation&#34;&gt;Gundersen, Kreider, and Pepper (2012)&lt;/span&gt;, among others.&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-angrist2009&#34;&gt;
&lt;p&gt;Angrist, J., and J. Pischke. 2009. &lt;em&gt;Mostly Harmless Econometrics&lt;/em&gt;. Princeton, NJ: Princeton University Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gundersen2012&#34;&gt;
&lt;p&gt;Gundersen, Craig, Brent Kreider, and John Pepper. 2012. “The Impact of the National School Lunch Program on Child Health: A Nonparametric Bounds Analysis.” &lt;em&gt;Journal of Econometrics&lt;/em&gt; 166 (1): 79–91.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kreider2007&#34;&gt;
&lt;p&gt;Kreider, Brent, and John Pepper. 2007. “Disability and Employment: Re-Evaluating the Evidence in Light of Reporting Errors.” &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 102: 432–41.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kreider2012&#34;&gt;
&lt;p&gt;Kreider, Brent, John Pepper, Craig Gundersen, and Dean Jolliffe. 2012. “Identifying the Effects of Snap (Food Stamps) on Child Health Outcomes When Participation Is Endogenous and Misreported.” &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 107: 958–75.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-manski2000&#34;&gt;
&lt;p&gt;Manski, Charles, and John Pepper. 2000. “Monotone Instrumental Variables: With an Application to the Returns to Schooling.” &lt;em&gt;Econometrica&lt;/em&gt; 68: 997–1010.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-millimet2013&#34;&gt;
&lt;p&gt;Millimet, Daniel L, and Rusty Tchernis. 2013. “Estimation of Treatment Effects Without an Exclusion Restriction: With an Application to the Analysis of the School Breakfast Program.” &lt;em&gt;Journal of Applied Econometrics&lt;/em&gt; 28: 982–1017.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Invalid Instruments</title>
      <link>/iv/step1b_exog_excl/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1b_exog_excl/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;blockquote&gt;
&lt;p&gt;“The best laid plans of mice and men often go awry”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;No matter how great you think your instrument is, your data may say otherwise. Maybe your “zero-first-stage” test fails, or maybe you have an overidentified model and you reject your Sargan or Hansen’s &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; test. Whatever the reason, you’re here because you’re starting to suspect that your instruments aren’t all you’d hoped.&lt;/p&gt;
&lt;p&gt;Let’s assume that you still have a strong first stage. If not, then you may need another estimation strategy altogether.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some violations...</title>
      <link>/iv/step1b_overall/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1b_overall/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;If you’re here, it means you’re uncomfortable with some of the required IV assumptions. Either you have some statistical evidence that your assumptions may not hold, or you suspect some violation of assumptions that you can’t test (e.g., the exogeneity assumption in a just-identified model). Or maybe you think everything is great but a reviewer thinks otherwise.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/l2JdVe261WWlx78BO/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Either way, the goal now is to consider treatment effect estimates that are robust to violations of some of the key IV assumptions. Click on the links below for more detail:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;/iv/step1b_firststage&#34;&gt;First stage&lt;/a&gt;: Weak instruments&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;/iv/step1b_exog_excl&#34;&gt;Exogeneity/Excludability&lt;/a&gt;: Instruments are also endogenous or directly affect the outcome&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Weak Instruments</title>
      <link>/iv/step1b_firststage/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1b_firststage/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;What do we do if we have weak instruments?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/3oFzlXvco5Wt2gnMcg/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I guess one option is to go look for better instruments, but I’m going to assume you’ve already identified your best potential instruments.&lt;/p&gt;
&lt;div id=&#34;weak-iv-robust-inference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Weak IV robust inference&lt;/h1&gt;
&lt;p&gt;Let’s assume we have our usual equation of interest, &lt;span class=&#34;math display&#34;&gt;\[y = x_{1} \beta_{1} + x_{2} \beta_{2} + \varepsilon,\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(x_{1}\)&lt;/span&gt; is assumed to be endogenous and &lt;span class=&#34;math inline&#34;&gt;\(x_{2}\)&lt;/span&gt; exogenous. We have some instruments, &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, that are correlated with &lt;span class=&#34;math inline&#34;&gt;\(x_{1}\)&lt;/span&gt;. But, we’re concerned that this correlation may be relatively low. Regardless, the coefficient of interest is still &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1}\)&lt;/span&gt;, and so one approach to dealing with weak IVs is to develop a test of &lt;span class=&#34;math inline&#34;&gt;\(H_{0}: \beta_{1}=0\)&lt;/span&gt; that is robust to weak instruments.&lt;/p&gt;
&lt;p&gt;One approach to this is the Anderson-Rubin test &lt;span class=&#34;citation&#34;&gt;(Anderson, Rubin, and others 1949)&lt;/span&gt;. This is a test of &lt;span class=&#34;math inline&#34;&gt;\(H_{0}: \gamma_{1} = 0\)&lt;/span&gt; in the “reduced-form”, &lt;span class=&#34;math display&#34;&gt;\[y = z \gamma_{1} + x_{2} \gamma_{2} + \nu.\]&lt;/span&gt; If we reject this test (i.e., there is evidence that &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{1} \neq 0\)&lt;/span&gt;) then it is also evidence that &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1} \neq 0\)&lt;/span&gt;. That’s because, with weak instruments, the coefficient on &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; in the first stage regression of &lt;span class=&#34;math inline&#34;&gt;\(x_{1}\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_{2}\)&lt;/span&gt; is close to 0 and would tend to decrease the probability of rejecting the null of &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{1}=0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Chernozhukov and Hansen (2008)&lt;/span&gt; extends this approach by constructing a confidence interval for &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1}\)&lt;/span&gt; that is robust to weak instruments. Using our current notation, they propose the following process:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Pick a value, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, for &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Construct &lt;span class=&#34;math inline&#34;&gt;\(\tilde{y} = y - x_{1} b\)&lt;/span&gt; and regress &lt;span class=&#34;math inline&#34;&gt;\(\tilde{y}\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_{2}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Calculate the Wald statistic for &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(W(b) = \hat{\gamma}&amp;#39; Var(\hat{\gamma})^{-1} \hat{\gamma} \sim \chi ^{2}_{r}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Construct the confidence region as the set of &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(W_{s}(b) \leq c(1-p)\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(c(1-p)\)&lt;/span&gt; is the &lt;span class=&#34;math inline&#34;&gt;\((1-p)^{th}\)&lt;/span&gt; percentile of the &lt;span class=&#34;math inline&#34;&gt;\(\chi^{2}_{r}\)&lt;/span&gt; distribution (&lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the number of instruments).&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;two-step-robust-inference&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Two-step robust inference&lt;/h1&gt;
&lt;p&gt;One issue with the above approach is that we are really considering a two-stage process. In stage 1, we assess the general strength of the instrument, and in stage 2, if we’ve identified evidence of a weak instrument, then we pursue some form of weak IV robust inference. But failure to account for the first stage in our second stage confidence intervals could lead to some problems, such that we may incorrectly reject the null. This is where some recent methods in &lt;span class=&#34;citation&#34;&gt;Finlay and Magnusson (2009)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Andrews (2018)&lt;/span&gt; can help in developing confidence intervals that appropriately account for the first-stage of this process. Commands to estimate such confidence intervals are available in Stata with &lt;code&gt;weakiv&lt;/code&gt; and &lt;code&gt;twostepweakiv&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;The result of these intervals, for the purposes of weak IV robust inference, is a range of values &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; such that the null &lt;span class=&#34;math inline&#34;&gt;\(H_{0}: \beta_{1}=b\)&lt;/span&gt; cannot be rejected (at the given significance level used to construct the interval).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-anderson1949&#34;&gt;
&lt;p&gt;Anderson, Theodore W, Herman Rubin, and others. 1949. “Estimation of the Parameters of a Single Equation in a Complete System of Stochastic Equations.” &lt;em&gt;The Annals of Mathematical Statistics&lt;/em&gt; 20 (1): 46–63.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-andrews2018&#34;&gt;
&lt;p&gt;Andrews, Isaiah. 2018. “Valid Two-Step Identification-Robust Confidence Sets for Gmm.” &lt;em&gt;Review of Economics and Statistics&lt;/em&gt; 100 (2): 337–48.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-chernozhukov2008&#34;&gt;
&lt;p&gt;Chernozhukov, Victor, and Christian Hansen. 2008. “The Reduced Form: A Simple Approach to Inference with Weak Instruments.” &lt;em&gt;Economics Letters&lt;/em&gt; 100 (1): 68–71.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-finlay2009&#34;&gt;
&lt;p&gt;Finlay, Keith, and Leandro M Magnusson. 2009. “Implementing Weak-Instrument Robust Tests for a General Class of Instrumental-Variables Models.” &lt;em&gt;The Stata Journal&lt;/em&gt; 9 (3): 398–421.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Testing for Exogeneity</title>
      <link>/iv/step1_exog/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1_exog/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Unfortunately, this is again an area where I’ve already oversold the topic. In general, we can’t test for instrument exogeneity. It’s just one of those assumptions that we have to maintain if we’re going to use IV.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/3ohhwAUoWvd7BeEkqA/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But all is not lost. We can (somewhat) test this assumption if we have more instruments than we do endogenous variables (i.e., if we have an overidentified model). With homoskedastic errors, we run a Sargan test, and with heteroskedastic errors, we use the Hansen’s &lt;em&gt;J&lt;/em&gt; test &lt;span class=&#34;citation&#34;&gt;(Sargan 1958, @hansen1982)&lt;/span&gt;. Each test is readily available in Stata’s &lt;code&gt;ivreg&lt;/code&gt; command. For R users, The Sargan test is part of &lt;code&gt;ivreg&lt;/code&gt; diagnostics, but the Hansen’s &lt;em&gt;J&lt;/em&gt; test isn’t immediately available without employing other estimators from other packages. So R users have to do a little bit more work, or you can use the &lt;code&gt;RStata&lt;/code&gt; package and run Stata code in R.&lt;/p&gt;
&lt;p&gt;Finally, note that the null in each test is that your instruments are exogenous. Rejecting the null therefore suggests we might have a problem. But failing to reject the null doesn’t necessarily mean exogeneity holds. So, there’s that.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/fo2kRfu3C4Cz3pmlka/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-hansen1982&#34;&gt;
&lt;p&gt;Hansen, Lars Peter. 1982. “Large Sample Properties of Generalized Method of Moments Estimators.” &lt;em&gt;Econometrica: Journal of the Econometric Society&lt;/em&gt;, 1029–54.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-sargan1958&#34;&gt;
&lt;p&gt;Sargan, John D. 1958. “The Estimation of Economic Relationships Using Instrumental Variables.” &lt;em&gt;Econometrica: Journal of the Econometric Society&lt;/em&gt;, 393–415.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Testing the Exclusion Restriction</title>
      <link>/iv/step1_exclude/</link>
      <pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1_exclude/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The exclusion restriction says that your instruments do not directly affect your outcome, so that it is appropriately “excluded” from the main equation of interest. This assumption goes by different names and is sometimes combined with other IV assumptions. For example, sometimes you see this assumption lumped into the first stage requirement and stated as an “only-through” assumption (i.e., the instrument affects the outcome only through the endogenous variable of interest).&lt;/p&gt;
&lt;p&gt;Regardless, the exclusion restriction is hard to test because the instrument should also be correlated with the endogenous variable of interest. Isolating variation coming only from the instrument, separately from any variation coming from the instrument via the endogenous variable, is not feasible in a general setting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/UTX8UTKmpjQgo/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But don’t lose all hope yet. There are a couple of things we can do. One initial test is what &lt;span class=&#34;citation&#34;&gt;Kippersluis and Rietveld (2018)&lt;/span&gt; refers to as a “zero-first-stage” test. The idea is that you have a subsample for which your instrument is not correlated with the endogenous variable of interest. You then regress the outcome on all covariates and the instruments, among the subsample for which there is no first stage effect. The resulting coefficient on the instruments then captures any potential direct effect of the instruments on the outcome (since the correlation with the endogenous variable is 0 by assumption).&lt;/p&gt;
&lt;p&gt;You can go a little further with this, as shown in &lt;span class=&#34;citation&#34;&gt;Altonji, Elder, and Taber (2005)&lt;/span&gt;, and use this approach to directly estimate the extent of the bias from violations of the exclusion restriction. However, a more recent approach to deal with violations of the exclusion restriction is in &lt;span class=&#34;citation&#34;&gt;Conley, Hansen, and Rossi (2012)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Kippersluis and Rietveld (2018)&lt;/span&gt;, which I discuss in more detail in &lt;a href=&#34;/iv/step1b_exclude&#34;&gt;Step 1B: Violations of the exclusion restriction&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have an overidentified model, then you can test the exclusion restriction alongside the exogeneity assumption for a subset of instruments &lt;span class=&#34;citation&#34;&gt;(Beckert 2020)&lt;/span&gt;. Paraphrasing &lt;span class=&#34;citation&#34;&gt;Beckert (2020)&lt;/span&gt;, assuming we have &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; instruments and &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; endogenous variables, then under the maintained assumption that there are at least &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; valid instruments, you can test the null that all instruments are valid against the alternative that up to &lt;span class=&#34;math inline&#34;&gt;\(m - n\)&lt;/span&gt; instruments are valid.&lt;/p&gt;
&lt;p&gt;We can implement this test easily. First, we estimate the first-stage regressions (regression of our endogenous variables on the instruments and all other exogenous variables). Second, we save the residuals from these regressions, denoted &lt;span class=&#34;math inline&#34;&gt;\(\hat{u}\)&lt;/span&gt;. Third, we estimate the “artificial” regression &lt;span class=&#34;math display&#34;&gt;\[y = \beta x + \delta \tilde{z} + \gamma \hat{u} + \varepsilon,\]&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\tilde{z}\)&lt;/span&gt; denotes a subset of &lt;span class=&#34;math inline&#34;&gt;\(m-n\)&lt;/span&gt; instruments from the full instrument matrix &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;. We then test the null that &lt;span class=&#34;math inline&#34;&gt;\(\delta=0\)&lt;/span&gt; using a standard F-test.&lt;/p&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-altonji2005&#34;&gt;
&lt;p&gt;Altonji, Joseph G, Todd E Elder, and Christopher R Taber. 2005. “An Evaluation of Instrumental Variable Strategies for Estimating the Effects of Catholic Schooling.” &lt;em&gt;Journal of Human Resources&lt;/em&gt; 40 (4): 791–821.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-beckert2020&#34;&gt;
&lt;p&gt;Beckert, Walter. 2020. “A Note on Specification Testing in Some Structural Regression Models.” &lt;em&gt;Oxford Bulletin of Economics and Statistics&lt;/em&gt; 82 (3): 686–95.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-conley2012&#34;&gt;
&lt;p&gt;Conley, Timothy G, Christian B Hansen, and Peter E Rossi. 2012. “Plausibly Exogenous.” &lt;em&gt;Review of Economics and Statistics&lt;/em&gt; 94 (1): 260–72.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kippersluis2018&#34;&gt;
&lt;p&gt;Kippersluis, Hans van, and Cornelius A Rietveld. 2018. “Beyond Plausibly Exogenous.” &lt;em&gt;The Econometrics Journal&lt;/em&gt; 21 (3): 316–31.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Are your instruments any good?</title>
      <link>/iv/step1_overall/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1_overall/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;If you’ve made it this far, then you are confident that you have some real endogeneity problems and that IV is at least a possibility. Before going any further, we have to put your instruments to the test. Cue the montage.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/3oz8xFAkMSb1RnZpNm/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This stage is all about testing the three key assumptions to any IV. Click on the links below to go to more detail on each assumption, or go back to the &lt;a href=&#34;/iv/flowchart&#34;&gt;flowchart&lt;/a&gt;.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;/iv/step1_firststage&#34;&gt;First stage&lt;/a&gt;: Our instrument must be correlated with the endogenous variable of interest.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;/iv/step1_exog&#34;&gt;Exogeneity&lt;/a&gt;: Our instrument must be exogenous.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;/iv/step1_exclude&#34;&gt;Excludability&lt;/a&gt;: The instrument must be correlated with the outcome, but only through the endogenous variable.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>How big is the problem?</title>
      <link>/endog/problem/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/endog/problem/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;It would be great if we could test for whether we really had an endogeneity problem or not. But alas, that’s just not in the cards. Instead, a good starting point is just to see “how much” of endogeneity problem we’d have to have to overturn our current results.&lt;/p&gt;
&lt;div id=&#34;coefficient-stability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Coefficient Stability&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;Oster (2019)&lt;/span&gt; can help us here. Here’s the idea…&lt;/p&gt;
&lt;p&gt;Lots of applied researchers assess “coefficient stability” by including different sets of control variables that are intended to proxy for some potentially important unobserved factor. This is not informative of omitted variables bias if the existing controls already do a very poor job of explaining the outcome. As Prof. Oster notes, “Omitted variable bias is proportional to coefficient movements, but only if such movements are scaled by the change in R-squared when controls are included.”&lt;/p&gt;
&lt;p&gt;Extending the work of &lt;span class=&#34;citation&#34;&gt;Altonji, Elder, and Taber (2005)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;Oster (2019)&lt;/span&gt; lays out a scenario in which we can fully decompose our outcome of interest into a treatment effect (denoted &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;), observed controls (denoted by &lt;span class=&#34;math inline&#34;&gt;\(W_{1}\)&lt;/span&gt;), unobserved controls (denoted by &lt;span class=&#34;math inline&#34;&gt;\(W_{2}\)&lt;/span&gt;), and some iid error term. Denote by &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; the treatment variable, such that &lt;span class=&#34;math display&#34;&gt;\[Y = \beta X + W_{1} + W_{2} + \epsilon.\]&lt;/span&gt; We then need to consider values (or a range of values) for two key objects.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What is the maximum &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; value we could obtain if we observed &lt;span class=&#34;math inline&#34;&gt;\(W_{2}\)&lt;/span&gt;? Let’s call this &lt;span class=&#34;math inline&#34;&gt;\(R_{\text{max}}^{2}\)&lt;/span&gt;. If we think the outcome is fully deterministic if we were to observe all relevant variables, then &lt;span class=&#34;math inline&#34;&gt;\(R_{\text{max}}^{2}=1\)&lt;/span&gt;, but we could consider smaller values as well.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the degree of selection on observed variables relative to unobserved variables? We can denote this value as &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;, and define &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; as the value such that: &lt;span class=&#34;math display&#34;&gt;\[\delta \times \frac{Cov(W_{1},X)}{Var(W_{1})} = \frac{Cov(W_{2},X)}{Var(W_{2})}.\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We then need to define a few objects that we can directly estimate with the data:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Denote by &lt;span class=&#34;math inline&#34;&gt;\(R^{2}_{X}\)&lt;/span&gt; the &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; from a regression of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; on treatment (and only treatment, no covariates). Similarly denote by &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{X}\)&lt;/span&gt; the value of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; estimated from that regression.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Denote by &lt;span class=&#34;math inline&#34;&gt;\(R^{2}_{X,W_{1}}\)&lt;/span&gt; the &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; from a regression of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; on treatment and observed controls. Again, denote the estimated value of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; from this regression as &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{X, W_{1}}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Under the assumption that the relative size of coefficients from a regression of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and observed variables are equal to those from a regression of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and the observed variables, &lt;span class=&#34;citation&#34;&gt;Oster (2019)&lt;/span&gt; then shows that the true coefficient of interest (&lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; from the full regression) converges to the following:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\beta^{*} \approx \hat{\beta}_{X,W_{1}} - \delta \times \left[\hat{\beta}_{X} - \hat{\beta}_{X,W_{1}}\right] \times \frac{R_{max}^{2} - R_{X,W_{1}}^{2}}{R_{X,W_{1}}^{2} - R_{X}^{2}} \xrightarrow{p} \beta.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we relax the assumption of equal “relative contributions” between the observed covariates and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; versus the observed covariates and &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, then the results are a little more complicated. In that case, &lt;span class=&#34;citation&#34;&gt;Oster (2019)&lt;/span&gt; shows that &lt;span class=&#34;math display&#34;&gt;\[\beta^{*} = \hat{\beta}_{X,W_{1}} - \nu_{1} \xrightarrow{p} \beta,\]&lt;/span&gt; or &lt;span class=&#34;math display&#34;&gt;\[\beta^{*} \in \left\{ \hat{\beta}_{X,W_{1}} - \nu_{1}, \hat{\beta}_{X,W_{1}} - \nu_{2}, \hat{\beta}_{X,W_{1}} - \nu_{3} \right\},\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\nu_{1}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\nu_{2}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\nu_{3}\)&lt;/span&gt; are roots of a cubic function, &lt;span class=&#34;math inline&#34;&gt;\(f(\nu)\)&lt;/span&gt;, derived in the paper. In the case of more than one root, then one element of &lt;span class=&#34;math inline&#34;&gt;\(\beta^{*}\)&lt;/span&gt; converges in probability to &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(\delta=1\)&lt;/span&gt;, then some additional simplifications can be made, but the point is that we now have an expression for the bias as a function of &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(R^{2}_{max}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So what do we gain from all of this? Well, &lt;span class=&#34;citation&#34;&gt;Oster (2019)&lt;/span&gt; shows that we can also work backwards and find the value of &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(\beta=0\)&lt;/span&gt;. In other words, say we estimate using OLS some effect, &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{X, W_{1}}\)&lt;/span&gt;. How big must the role of selection on unobservables be in order to completely overpower our estimate such that the true effect is actually 0?&lt;/p&gt;
&lt;p&gt;Another approach is to consider a range of &lt;span class=&#34;math inline&#34;&gt;\(R^{2}_{max}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; to bound the estimated treatment effect. Using &lt;span class=&#34;math inline&#34;&gt;\(\delta=1\)&lt;/span&gt; as an upper bound for &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; (i.e., observables are at least as important as the unobservables), and &lt;span class=&#34;math inline&#34;&gt;\(\bar{R}^{2}_{max}\)&lt;/span&gt; as an upper bound for &lt;span class=&#34;math inline&#34;&gt;\(R^{2}_{max}\)&lt;/span&gt;, then the bounds on &lt;span class=&#34;math inline&#34;&gt;\(\beta^{*}\)&lt;/span&gt; are &lt;span class=&#34;math inline&#34;&gt;\(\left[ \hat{\beta}_{X,W_{1}}, \beta^{*}(\bar{R}^{2}_{max}, 1) \right]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, &lt;span class=&#34;citation&#34;&gt;Oster (2019)&lt;/span&gt; suggests setting &lt;span class=&#34;math inline&#34;&gt;\(\delta=1\)&lt;/span&gt; and identifying the value of &lt;span class=&#34;math inline&#34;&gt;\(R^{2}_{max}\)&lt;/span&gt; for which &lt;span class=&#34;math inline&#34;&gt;\(\beta=0\)&lt;/span&gt;. This would tell us how much of the variation in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; would need to be explained by unobservables in order for the true effect to be null (given our estimate, &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{X,W_{1}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There is also a Stata command, &lt;code&gt;psacalc&lt;/code&gt;, to do these calculations for us!&lt;br /&gt;
# References&lt;/p&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-altonji2005&#34;&gt;
&lt;p&gt;Altonji, Joseph G, Todd E Elder, and Christopher R Taber. 2005. “An Evaluation of Instrumental Variable Strategies for Estimating the Effects of Catholic Schooling.” &lt;em&gt;Journal of Human Resources&lt;/em&gt; 40 (4): 791–821.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-oster2019&#34;&gt;
&lt;p&gt;Oster, Emily. 2019. “Unobservable Selection and Coefficient Stability: Theory and Evidence.” &lt;em&gt;Journal of Business &amp;amp; Economic Statistics&lt;/em&gt; 37 (2): 187–204. &lt;a href=&#34;https://doi.org/10.1080/07350015.2016.1227711&#34;&gt;https://doi.org/10.1080/07350015.2016.1227711&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How big is the problem?</title>
      <link>/iv/problem/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/problem/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;It would be great if we could test for whether we need IV or not. But unfortunately, I’ve already oversold this section. There is no magic “test” for whether you need IV.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/oXB0K4oFw3fck/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But all is not lost. Even though we can’t definitively say that we &lt;em&gt;need&lt;/em&gt; to use IV we can at least see different some IV results might be relative to OLS (assuming we have some decent instruments already).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/ZExucn4EDMUtX0p9dt/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;iv-vs-ols&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;IV vs OLS&lt;/h2&gt;
&lt;p&gt;An easy way to assess the need for IV is to simply test whether your IV results are sufficiently different from OLS. That’s the spirit of the Hausman test. The original test introduced in &lt;span class=&#34;citation&#34;&gt;Hausman (1978)&lt;/span&gt; is not specific to endogeneity…it’s a more general misspecification test, comparing the estimates from one estimator (that is efficient under the null) to that of another estimator that is consistent but inefficient under the null. The test in the context of IV is also referred to as the Durbin-Wu-Hausman test, due to the series of papers pre-dating &lt;span class=&#34;citation&#34;&gt;Hausman (1978)&lt;/span&gt;, including &lt;span class=&#34;citation&#34;&gt;Durbin (1954)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;Wu (1973)&lt;/span&gt;, and &lt;span class=&#34;citation&#34;&gt;Wu (1974)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This test is easily implemented as an “artificial” or “augmented” regression. Denoting our outcome by &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, our instruments by &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;, our endogeous variables by &lt;span class=&#34;math inline&#34;&gt;\(x_{1}\)&lt;/span&gt;, and other exogenous variables by &lt;span class=&#34;math inline&#34;&gt;\(x_{2}\)&lt;/span&gt;, we first regress each of the variables in &lt;span class=&#34;math inline&#34;&gt;\(x_{1}\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(x_{2}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;. Then we take the residuals from those regressions, denoted &lt;span class=&#34;math inline&#34;&gt;\(\hat{v}\)&lt;/span&gt;, and include them in the standard OLS regression of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(x_{1}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_{2}\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\hat{v}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The biggest barrier to this test in practice is that it assumes we have a valid and strong set of instruments, &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;. Since that’s usually the biggest barrier to causal inference with IV, it becomes a major practical problem. For example, if you reject the null and conclude that estimates from OLS and IV are statistically different, can you be sure that the difference is “real” and not a statistical artifact of weak or invalid instruments? The whole process becomes pretty circular.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/dyGiQTZrrASFWp9qP8/source.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-durbin1954&#34;&gt;
&lt;p&gt;Durbin, James. 1954. “Errors in Variables.” &lt;em&gt;Revue de L’institut International de Statistique&lt;/em&gt;, 23–32.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hausman1978&#34;&gt;
&lt;p&gt;Hausman, Jerry A. 1978. “Specification Tests in Econometrics.” &lt;em&gt;Econometrica: Journal of the Econometric Society&lt;/em&gt;, 1251–71.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wu1973&#34;&gt;
&lt;p&gt;Wu, De-Min. 1973. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances.” &lt;em&gt;Econometrica: Journal of the Econometric Society&lt;/em&gt;, 733–50.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wu1974&#34;&gt;
&lt;p&gt;———. 1974. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances: Finite Sample Results.” &lt;em&gt;Econometrica: Journal of the Econometric Society&lt;/em&gt;, 529–46.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Testing the First Stage</title>
      <link>/iv/step1_firststage/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/iv/step1_firststage/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The “first stage” is just a common term for a regression of the endogenous variable, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, on your instrument, &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; (and any other exogenous variables). If you have more than one endogeous variable, then you will have more than one first stage, but all of your instruments should be in each of those regressions. The intuition is simple, if you have a proposed instrument, it should at least be correlated with your endogenous variable of interest (after conditioning on all other exogenous variables already in the model). As with lots of econometrics, this sounds simple until it’s not. To preview some of this complexity, I’m only focusing on linear IV models here…the literature on non-linear IV models is less developed as far as I can tell.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/14xS2Ey9TXH0Gs/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;underidentification-versus-weak-instruments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Underidentification versus weak instruments&lt;/h2&gt;
&lt;p&gt;It is easy to confuse the question of underidentification versus weak instruments, but they are different issues. In the case of underidentification, we are explicitly interested in testing whether the partial correlation between the instrument(s) and the endogenous variable(s) is 0. In other words, is the instrument matrix of full rank? But it is possible to reject the null that the instruments and endogenous variables are uncorrelated, while still have very weak instruments. The literature therefore distinguishes between tests of 0 correlation versus tests that are robust to weak instruments (e.g., a test for which rejection of the null suggests that the instruments are sufficiently “strong”). Luckily, this distinction relates to the critical value to which you compare a given test statistic. In other words, a test of underidentification can use standard critical values, while a test allowing for weak instruments will tend to require slightly higher critical values (harder to reject).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;one-endogenous-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;One endogenous variable&lt;/h2&gt;
&lt;p&gt;This is the simplest possible setup, and one in which you essentially focus on the significance (or, in the case of more than one instrument, joint significance) of your instruments in a regression of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; on &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt; and all other exogenous variables. A standard t-test or F-test using traditional critical values would be a test of underidentification.&lt;/p&gt;
&lt;p&gt;As is well-known, an F-stat of 10 is considered a decent rule-of-thumb for testing the first stage. This value was first proposed in &lt;span class=&#34;citation&#34;&gt;Staiger and Stock (1997)&lt;/span&gt;, and it’s important because it’s larger than the standard critical values. The reason it’s larger is because the &lt;span class=&#34;citation&#34;&gt;Staiger and Stock (1997)&lt;/span&gt; critical values allow for weak instruments. While the rule-of-thumb value of 10 is common and useful, the literature has probably taken this threshold a little too seriously (see Figure 1 in &lt;span class=&#34;citation&#34;&gt;Andrews, Stock, and Sun (2019)&lt;/span&gt;, which shows a big spike at 10 in the empirical distribution of reported F-stats among papers published in the AER).&lt;/p&gt;
&lt;p&gt;Another popular first-stage assessment is the partial &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt;, sometimes called Shea’s Partial &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; &lt;span class=&#34;citation&#34;&gt;(Shea 1997)&lt;/span&gt;. This is the &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; of a regression of our endogenous variable on the instruments after partialling out the other exogenous variables. In other words, we regress our endogenous variable on our instrument(s), and we regress each of the exogenous covariates on our instrument(s). We then take the residual from each of those regressions and run another regression of the residualized endogenous variable against the residualized instruments. The &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; of that regression is the partial &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; because the influence of the the other exogenous variables has been removed. If the partial &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; is “low”, then we should suspect that our instruments are weak. The problem is that there is no clear value for “low” or “high”, and the distribution of this statistic is nonstandard. I suspect that, for this reason, Shea’s Partial &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; is not a commonly-reported measure of instrument strength in most published work.&lt;/p&gt;
&lt;p&gt;Finally, &lt;span class=&#34;citation&#34;&gt;Olea and Pflueger (2013)&lt;/span&gt; propose an “effective” F-stat that allows for heteroskedasticity. This hasn’t received much attention in the applied literature, but &lt;span class=&#34;citation&#34;&gt;Andrews, Stock, and Sun (2019)&lt;/span&gt; encourages wider adoption of such a test. You can implement this in Stata with &lt;code&gt;weakivtest&lt;/code&gt;. The effective F-stat is equivalent to a robust F-stat (i.e., the usual first-stage F-stat using robust standard errors) in the case of a single instrument. But with multiple instruments and one endogenous variable, the effective F-stat looks to be the best option for assessing the strength of your instruments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-endogenous-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple endogenous variables&lt;/h2&gt;
&lt;p&gt;With more than one endogenous variable, &lt;span class=&#34;citation&#34;&gt;Stock and Yogo (2005)&lt;/span&gt; develops critical values based on the Cragg-Donald statistic &lt;span class=&#34;citation&#34;&gt;(Cragg and Donald 1993)&lt;/span&gt;. A statistic similar to Cragg-Donald is the Anderson LM statistic, both of which are readily reported in Stata’s &lt;code&gt;ivreg2&lt;/code&gt; command. Unfortunately, both statistics require the assumption of homoskedastic errors. Shea’s Partial &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; also isn’t particularly informative in the case of multiple endogenous variables, again a potential reason for its limited use in practice.&lt;/p&gt;
&lt;p&gt;In the more realistic heteroskedastic setting, the appropriate tests are more complicated. The Kleibergen-Paap rank-based (&lt;em&gt;rk&lt;/em&gt;) statistic can be used to implement a Lagrange-Multiplier (LM) test that is a robust version of the Cragg-Donald statistic &lt;span class=&#34;citation&#34;&gt;(Kleibergen and Paap 2006)&lt;/span&gt;; however, the Kleibergen-Paap LM test is purely an “underidentification” test, and it is possible to reject the null while still having very weak correlation between your instruments and endogenous variables. For inference that is robust to weak instruments and heteroskedasticity, we can employ the Kleibergen-Paap &lt;em&gt;rk&lt;/em&gt; Wald test with the critical values from &lt;span class=&#34;citation&#34;&gt;Stock and Yogo (2005)&lt;/span&gt;. This is the approach recommended in &lt;span class=&#34;citation&#34;&gt;Baum, Schaffer, and Stillman (2007)&lt;/span&gt;, although this approach is not formalized. The Kleibergen-Paap &lt;em&gt;rk&lt;/em&gt; Wald statistics is also only recommended for just-identified models.&lt;/p&gt;
&lt;p&gt;Note that the Cragg-Donald statistic or the Kleibergen-Paap &lt;em&gt;rk&lt;/em&gt; statistic each provide a single test statistic for all of the instruments and all of the endogenous variables. But what if you have more than one endogenous variable and just one of the IVs is predominatly driving the identification in all cases? In that case, it can be good to look at tests separately for each endogenous variable. &lt;span class=&#34;citation&#34;&gt;Angrist and Pischke (2009)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;Sanderson and Windmeijer (2016)&lt;/span&gt; provide such an approach.&lt;/p&gt;
&lt;p&gt;Ultimately, if you have more than one endogenous variables and the same number of instruments, then the Kleibergen-Paap &lt;em&gt;rk&lt;/em&gt; Wald test with critical values from &lt;span class=&#34;citation&#34;&gt;Stock and Yogo (2005)&lt;/span&gt; (or at least the rule-of-thumb critical value of 10) is the best option with heteroskedastic or clustered errors. I have not yet seen any tests for an overidentified model with more than one endogenous variable and heteroskedasticity. If you have such a model but feel strongly about including all of the instruments, then one approach would be to consider as a sensitivity analysis the just-identified version of your model with your subset of “best” instruments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references hanging-indent&#34;&gt;
&lt;div id=&#34;ref-andrews2019&#34;&gt;
&lt;p&gt;Andrews, Isaiah, James H Stock, and Liyang Sun. 2019. “Weak Instruments in Instrumental Variables Regression: Theory and Practice.” &lt;em&gt;Annual Review of Economics&lt;/em&gt; 11: 727–53.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-angrist2009&#34;&gt;
&lt;p&gt;Angrist, J., and J. Pischke. 2009. &lt;em&gt;Mostly Harmless Econometrics&lt;/em&gt;. Princeton, NJ: Princeton University Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-baum2007&#34;&gt;
&lt;p&gt;Baum, Christopher F, Mark E Schaffer, and Steven Stillman. 2007. “Enhanced Routines for Instrumental Variables/Generalized Method of Moments Estimation and Testing.” &lt;em&gt;The Stata Journal&lt;/em&gt; 7 (4): 465–506.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cragg1993&#34;&gt;
&lt;p&gt;Cragg, John G, and Stephen G Donald. 1993. “Testing Identifiability and Specification in Instrumental Variable Models.” &lt;em&gt;Econometric Theory&lt;/em&gt;, 222–40.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kleibergen2006&#34;&gt;
&lt;p&gt;Kleibergen, Frank, and Richard Paap. 2006. “Generalized Reduced Rank Tests Using the Singular Value Decomposition.” &lt;em&gt;Journal of Econometrics&lt;/em&gt; 133 (1): 97–126.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-olea2013&#34;&gt;
&lt;p&gt;Olea, José Luis Montiel, and Carolin Pflueger. 2013. “A Robust Test for Weak Instruments.” &lt;em&gt;Journal of Business &amp;amp; Economic Statistics&lt;/em&gt; 31 (3): 358–69.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-sanderson2016&#34;&gt;
&lt;p&gt;Sanderson, Eleanor, and Frank Windmeijer. 2016. “A Weak Instrument F-Test in Linear Iv Models with Multiple Endogenous Variables.” &lt;em&gt;Journal of Econometrics&lt;/em&gt; 190 (2): 212–21.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-shea1997&#34;&gt;
&lt;p&gt;Shea, John. 1997. “Instrument Relevance in Multivariate Linear Models: A Simple Measure.” &lt;em&gt;The Review of Economics and Statistics&lt;/em&gt; 79 (2): 348–52.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-staiger1997&#34;&gt;
&lt;p&gt;Staiger, Douglas, and James H Stock. 1997. “Instrumental Variables Regression with Weak Instruments.” &lt;em&gt;Econometrica&lt;/em&gt; 65 (3): 557–86.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-stock2005&#34;&gt;
&lt;p&gt;Stock, James H, and Motohiro Yogo. 2005. “Testing for Weak Instruments in Linear Iv Regression.” In &lt;em&gt;Identification and Inference for Econometric Models: Essays in Honor of Thomas Rothenberg&lt;/em&gt;. Cambridge University Press.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Instrumental Variables Flowchart</title>
      <link>/iv/flowchart/</link>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/iv/flowchart/</guid>
      <description>&lt;p&gt;Most of the nodes in the diagram below are clickable, which will take you to another page with much more detail on that specific issue. In practice, empirical work is not so linear, and there is typically a lot of recirculation among these steps. For example, you may have 2 endogenous variables and 4 instruments. You may find that 1 or 2 of those instruments are weak, and as you learn this information, you are constantly recirculating in stage 1. You may settle on 3 instruments that seem to work well. Then, in Stage 2, you may find that your results are very sensitive with those instruments, but less sensitive when relying on only 2 of those 3 instruments. So now you go back to step 1, evaluate just those 2 instruments, etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/l0IylOPCNkiqOgMyA/giphy.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The point is that empirical work in practice is messy. Ideally, we could set out our plan in advance and proceed accordingly, but there are some things we just can&amp;rsquo;t know until we see the data. All we can do is work through the process in good faith, assessing the quality of our empirical work based on sound statistics and econometrics.&lt;/p&gt;
&lt;p&gt;One final note. If you&amp;rsquo;re accessing this on an android mobile device, the flowcharts are going to look a little odd (probably huge). This is a known issue in rendering these types of diagrams. See this closed 
&lt;a href=&#34;https://github.com/mermaid-js/mermaid/issues/816&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;issue on GitHub&lt;/a&gt; and these unanswered 
&lt;a href=&#34;https://stackoverflow.com/search?q=%5Bmermaid%5D&amp;#43;chrome&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;posts on StackOverflow&lt;/a&gt;. If anyone has any suggestions for how to have this render on an android mobile browser, please let me know. Otherwise, happy instrumenting!&lt;/p&gt;
&lt;div class=&#34;mermaid&#34;&gt;
graph TD;
    linkStyle default interpolate basis
    A([&#34;Thinking of IV?&#34;]) --&gt; B([&#34;Does it really matter?&#34;])
    B --&gt; |&#34;yes!&#34;| C1([&#34;Are your instruments&lt;br&gt; any good?&#34;])
    B --&gt; |&#34;I guess not&#34;| C2([&#34;Nevermind:&lt;br&gt; try something else&#34;])
    subgraph one [&#34;Stage 1: Requirements for any IV&#34;]
    C1 --&gt; D1([&#34;first-stage&#34;])
    C1 --&gt; D2([&#34;exogeneity&#34;])
    C1 --&gt; D3([&#34;exclusion&#34;])
    D1 --&gt; E([&#34;assess instruments&#34;])
    D2 --&gt; E
    D3 --&gt; E
    end
    subgraph two [&#34;Stage 1b: Something is better than nothing&#34;]
    E --&gt; |&#34;kind of ok&#34;| e1([&#34;Some violations&#34;])
    e1 --&gt; f1([&#34;first-stage&#34;])
    e1 --&gt; f2([&#34;exogeneity/exclusion&#34;])
    f1 --&gt; g([&#34;pick something&#34;])
    f2 --&gt; g
    end
    subgraph three [&#34;Stage 2: Still not in the clear&#34;]
    E --&gt; |&#34;so far so good!&#34;| E1([&#34;How sensitive are&lt;br&gt; the results?&#34;])
    g --&gt; E1
    E1 --&gt; F1([&#34;IV is biased!&#34;])
    E1 --&gt; F2([&#34;what about outliers?&#34;])
    F1 --&gt; G([&#34;assess sensitivity&#34;])
    F2 --&gt; G
    end
    E --&gt; |&#34;ouch, no bueno&#34;| C2
    G --&gt; |&#34;um, define sensitive&#34;| C2
    G --&gt; |&#34;not too bad!&#34;| H([&#34;What am I&lt;br&gt; estimating, again?&#34;])
    H --&gt; |&#34;can I be done?&#34;| I([&#34;Go forth and write&lt;br&gt; that appendix!&#34;])
    click B &#34;/iv/problem&#34; &#34;Pre-testing&#34;
    click C1 &#34;/iv/step1_overall&#34; &#34;Stage 1&#34;
    click D1 &#34;/iv/step1_firststage&#34; &#34;Testing the first stage&#34;
    click D2 &#34;/iv/step1_exog&#34; &#34;Testing the exogeneity assumption&#34;
    click D3 &#34;/iv/step1_exclude&#34; &#34;Testing the exclusion assumption&#34;
    click E &#34;/iv/step1_assess&#34; &#34;Assessing your instrument tests&#34;
    click e1 &#34;/iv/step1b_overall&#34; &#34;IVs are OK, but not great&#34;
    click f1 &#34;/iv/step1b_firststage&#34; &#34;Weak IV Robust Inference&#34;
    click f2 &#34;/iv/step1b_exog_excl&#34; &#34;Invalid IVs&#34;
    click C2 &#34;/&#34; &#34;Try something else&#34;
    click I &#34;https://davidcard.berkeley.edu/papers/card-dellavigna-pagelimits.pdf&#34; &#34;Page limits are non-binding.&#34;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
