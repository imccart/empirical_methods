---
title: "How big is the problem?"
date: '2020-08-03'
output: 
  blogdown::html_document2:
    toc: TRUE
    toc_float: TRUE
    toc_depth: 3
bibliography: '../../BibTeX_Library.bib'
math: true
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>It would be great if we could test for whether we need IV or not. But unfortunately, I’ve already oversold this section. There is no magic “test” for whether you need IV.</p>
<p><img src="https://media.giphy.com/media/oXB0K4oFw3fck/giphy.gif" /></p>
<p>But all is not lost. Even though we can’t definitively say that we <em>need</em> to use IV we can at least see different some IV results might be relative to OLS (assuming we have some decent instruments already).</p>
<p><img src="https://media.giphy.com/media/ZExucn4EDMUtX0p9dt/giphy.gif" /></p>
<div id="iv-vs-ols" class="section level2">
<h2>IV vs OLS</h2>
<p>An easy way to assess the need for IV is to simply test whether your IV results are sufficiently different from OLS. That’s the spirit of the Hausman test. The original test introduced in <span class="citation">Hausman (1978)</span> is not specific to endogeneity…it’s a more general misspecification test, comparing the estimates from one estimator (that is efficient under the null) to that of another estimator that is consistent but inefficient under the null. The test in the context of IV is also referred to as the Durbin-Wu-Hausman test, due to the series of papers pre-dating <span class="citation">Hausman (1978)</span>, including <span class="citation">Durbin (1954)</span>, <span class="citation">Wu (1973)</span>, and <span class="citation">Wu (1974)</span>.</p>
<p>This test is easily implemented as an “artificial” or “augmented” regression. Denoting our outcome by <span class="math inline">\(y\)</span>, our instruments by <span class="math inline">\(z\)</span>, our endogeous variables by <span class="math inline">\(x_{1}\)</span>, and other exogenous variables by <span class="math inline">\(x_{2}\)</span>, we first regress each of the variables in <span class="math inline">\(x_{1}\)</span> on <span class="math inline">\(x_{2}\)</span> and <span class="math inline">\(z\)</span>. Then we take the residuals from those regressions, denoted <span class="math inline">\(\hat{v}\)</span>, and include them in the standard OLS regression of <span class="math inline">\(y\)</span> on <span class="math inline">\(x_{1}\)</span>, <span class="math inline">\(x_{2}\)</span>, and <span class="math inline">\(\hat{v}\)</span>.</p>
<p>The biggest barrier to this test in practice is that it assumes we have a valid and strong set of instruments, <span class="math inline">\(z\)</span>. Since that’s usually the biggest barrier to causal inference with IV, it becomes a major practical problem. For example, if you reject the null and conclude that estimates from OLS and IV are statistically different, can you be sure that the difference is “real” and not a statistical artifact of weak or invalid instruments? The whole process becomes pretty circular.</p>
<p><img src="https://media.giphy.com/media/dyGiQTZrrASFWp9qP8/source.gif" /></p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-durbin1954">
<p>Durbin, James. 1954. “Errors in Variables.” <em>Revue de L’institut International de Statistique</em>, 23–32.</p>
</div>
<div id="ref-hausman1978">
<p>Hausman, Jerry A. 1978. “Specification Tests in Econometrics.” <em>Econometrica: Journal of the Econometric Society</em>, 1251–71.</p>
</div>
<div id="ref-wu1973">
<p>Wu, De-Min. 1973. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances.” <em>Econometrica: Journal of the Econometric Society</em>, 733–50.</p>
</div>
<div id="ref-wu1974">
<p>———. 1974. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances: Finite Sample Results.” <em>Econometrica: Journal of the Econometric Society</em>, 529–46.</p>
</div>
</div>
</div>
