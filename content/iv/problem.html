---
title: "Pre-testing the Need for IV"
date: '2020-08-03'
output: 
  blogdown::html_document2:
    toc: TRUE
    toc_float: TRUE
    toc_depth: 3
bibliography: 'D:/CloudStation/Professional/Bibliography/BibTeX_Library.bib'
math: true
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>I’ve already oversold this section. There is no magic “test” for whether you need IV.</p>
<p><img src="https://media.giphy.com/media/oXB0K4oFw3fck/giphy.gif" /></p>
<p>But all is not lost. There are a couple of things that we can try. While these approaches won’t definitively point us to IV, they will at least inform us as to the extent of the potential endogeneity problem and tell us how different some IV results might be relative to OLS (assuming we have some decent instruments already).</p>
<p><img src="https://media.giphy.com/media/ZExucn4EDMUtX0p9dt/giphy.gif" /></p>
<div id="coefficient-stability" class="section level2">
<h2>Coefficient Stability</h2>
<p>A good first step is to quantify just how bad the endogeneity problem would need to be in order to negate your initial findings (say, from good ol’ OLS). <span class="citation">Oster (2019)</span> can help us here. Here’s the idea…</p>
<p>Lots of applied researchers assess “coefficient stability” by including different sets of control variables that are intended to proxy for some potentially important unobserved factor. This is not informative of omitted variables bias if the existing controls already do a very poor job of explaining the outcome. As Prof. Oster notes, “Omitted variable bias is proportional to coefficient movements, but only if such movements are scaled by the change in R-squared when controls are included.”</p>
<p>Extending the work of <span class="citation">Altonji, Elder, and Taber (2005)</span>, <span class="citation">Oster (2019)</span> lays out a scenario in which we can fully decompose our outcome of interest into a treatment effect (denoted <span class="math inline">\(\beta\)</span>), observed controls (denoted by <span class="math inline">\(W_{1}\)</span>), unobserved controls (denoted by <span class="math inline">\(W_{2}\)</span>), and some iid error term. Denote by <span class="math inline">\(X\)</span> the treatment variable, such that <span class="math display">\[Y = \beta X + W_{1} + W_{2} + \epsilon.\]</span> We then need to consider values (or a range of values) for two key objects.</p>
<ol style="list-style-type: decimal">
<li><p>What is the maximum <span class="math inline">\(R^2\)</span> value we could obtain if we observed <span class="math inline">\(W_{2}\)</span>? Let’s call this <span class="math inline">\(R_{\text{max}}^{2}\)</span>. If we think the outcome is fully deterministic if we were to observe all relevant variables, then <span class="math inline">\(R_{\text{max}}^{2}=1\)</span>, but we could consider smaller values as well.</p></li>
<li><p>What is the degree of selection on observed variables relative to unobserved variables? We can denote this value as <span class="math inline">\(\delta\)</span>, and define <span class="math inline">\(\delta\)</span> as the value such that: <span class="math display">\[\delta \times \frac{Cov(W_{1},X)}{Var(W_{1})} = \frac{Cov(W_{2},X)}{Var(W_{2})}.\]</span></p></li>
</ol>
<p>We then need to define a few objects that we can directly estimate with the data:</p>
<ol style="list-style-type: decimal">
<li><p>Denote by <span class="math inline">\(R^{2}_{X}\)</span> the <span class="math inline">\(R^{2}\)</span> from a regression of <span class="math inline">\(Y\)</span> on treatment (and only treatment, no covariates). Similarly denote by <span class="math inline">\(\hat{\beta}_{X}\)</span> the value of <span class="math inline">\(\beta\)</span> estimated from that regression.</p></li>
<li><p>Denote by <span class="math inline">\(R^{2}_{X,W_{1}}\)</span> the <span class="math inline">\(R^{2}\)</span> from a regression of <span class="math inline">\(Y\)</span> on treatment and observed controls. Again, denote the estimated value of <span class="math inline">\(\beta\)</span> from this regression as <span class="math inline">\(\hat{\beta}_{X, W_{1}}\)</span>.</p></li>
</ol>
<p>Under the assumption that the relative size of coefficients from a regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> and observed variables are equal to those from a regression of <span class="math inline">\(X\)</span> and the observed variables, <span class="citation">Oster (2019)</span> then shows that the true coefficient of interest (<span class="math inline">\(\beta\)</span> from the full regression) converges to the following:</p>
<p><span class="math display">\[\beta^{*} \approx \hat{\beta}_{X,W_{1}} - \delta \times \left[\hat{\beta}_{X} - \hat{\beta}_{X,W_{1}}\right] \times \frac{R_{max}^{2} - R_{X,W_{1}}^{2}}{R_{X,W_{1}}^{2} - R_{X}^{2}} \xrightarrow{p} \beta.\]</span></p>
<p>If we relax the assumption of equal “relative contributions” between the observed covariates and <span class="math inline">\(Y\)</span> versus the observed covariates and <span class="math inline">\(X\)</span>, then the results are a little more complicated. In that case, <span class="citation">Oster (2019)</span> shows that <span class="math display">\[\beta^{*} = \hat{\beta}_{X,W_{1}} - \nu_{1} \xrightarrow{p} \beta,\]</span> or <span class="math display">\[\beta^{*} \in \left\{ \hat{\beta}_{X,W_{1}} - \nu_{1}, \hat{\beta}_{X,W_{1}} - \nu_{2}, \hat{\beta}_{X,W_{1}} - \nu_{3} \right\},\]</span>
where <span class="math inline">\(\nu_{1}\)</span>, <span class="math inline">\(\nu_{2}\)</span>, and <span class="math inline">\(\nu_{3}\)</span> are roots of a cubic function, <span class="math inline">\(f(\nu)\)</span>, derived in the paper. In the case of more than one root, then one element of <span class="math inline">\(\beta^{*}\)</span> converges in probability to <span class="math inline">\(\beta\)</span>. If <span class="math inline">\(\delta=1\)</span>, then some additional simplifications can be made, but the point is that we now have an expression for the bias as a function of <span class="math inline">\(\delta\)</span> and <span class="math inline">\(R^{2}_{max}\)</span>.</p>
<p>So what do we gain from all of this? Well, <span class="citation">Oster (2019)</span> shows that we can also work backwards and find the value of <span class="math inline">\(\delta\)</span> such that <span class="math inline">\(\beta=0\)</span>. In other words, say we estimate using OLS some effect, <span class="math inline">\(\hat{\beta}_{X, W_{1}}\)</span>. How big must the role of selection on unobservables be in order to completely overpower our estimate such that the true effect is actually 0?</p>
<p>Another approach is to consider a range of <span class="math inline">\(R^{2}_{max}\)</span> and <span class="math inline">\(\delta\)</span> to bound the estimated treatment effect. Using <span class="math inline">\(\delta=1\)</span> as an upper bound for <span class="math inline">\(\delta\)</span> (i.e., observables are at least as important as the unobservables), and <span class="math inline">\(\bar{R}^{2}_{max}\)</span> as an upper bound for <span class="math inline">\(R^{2}_{max}\)</span>, then the bounds on <span class="math inline">\(\beta^{*}\)</span> are <span class="math inline">\(\left[ \hat{\beta}_{X,W_{1}}, \beta^{*}(\bar{R}^{2}_{max}, 1) \right]\)</span>.</p>
<p>Finally, <span class="citation">Oster (2019)</span> suggests setting <span class="math inline">\(\delta=1\)</span> and identifying the value of <span class="math inline">\(R^{2}_{max}\)</span> for which <span class="math inline">\(\beta=0\)</span>. This would tell us how much of the variation in <span class="math inline">\(Y\)</span> would need to be explained by unobservables in order for the true effect to be null (given our estimate, <span class="math inline">\(\hat{\beta}_{X,W_{1}}\)</span>.</p>
<p>There is also a Stata command, <code>psacalc</code>, to do these calculations for us!</p>
</div>
<div id="iv-vs-ols" class="section level2">
<h2>IV vs OLS</h2>
<p>An easy way to assess the need for IV is to simply test whether your IV results are sufficiently different from OLS. That’s the spirit of the Hausman test. The original test introduced in <span class="citation">Hausman (1978)</span> is not specific to endogeneity…it’s a more general misspecification test, comparing the estimates from one estimator (that is efficient under the null) to that of another estimator that is consistent but inefficient under the null. The test in the context of IV is also referred to as the Durbin-Wu-Hausman test, due to the series of papers pre-dating <span class="citation">Hausman (1978)</span>, including <span class="citation">Durbin (1954)</span>, <span class="citation">Wu (1973)</span>, and <span class="citation">Wu (1974)</span>.</p>
<p>This test is easily implemented as an “artificial” or “augmented” regression. Denoting our outcome by <span class="math inline">\(y\)</span>, our instruments by <span class="math inline">\(z\)</span>, our endogeous variables by <span class="math inline">\(x_{1}\)</span>, and other exogenous variables by <span class="math inline">\(x_{2}\)</span>, we first regress each of the variables in <span class="math inline">\(x_{1}\)</span> on <span class="math inline">\(x_{2}\)</span> and <span class="math inline">\(z\)</span>. Then we take the residuals from those regressions, denoted <span class="math inline">\(\hat{v}\)</span>, and include them in the standard OLS regression of <span class="math inline">\(y\)</span> on <span class="math inline">\(x_{1}\)</span>, <span class="math inline">\(x_{2}\)</span>, and <span class="math inline">\(\hat{v}\)</span>.</p>
<p>The biggest barrier to this test in practice is that it assumes we have a valid and strong set of instruments, <span class="math inline">\(z\)</span>. Since that’s usually the biggest barrier to causal inference with IV, it becomes a major practical problem. For example, if you reject the null and conclude that estimates from OLS and IV are statistically different, can you be sure that the difference is “real” and not a statistical artifact of weak or invalid instruments? The whole process becomes pretty circular.</p>
<p><img src="https://media.giphy.com/media/dyGiQTZrrASFWp9qP8/source.gif" /></p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-altonji2005">
<p>Altonji, Joseph G, Todd E Elder, and Christopher R Taber. 2005. “An Evaluation of Instrumental Variable Strategies for Estimating the Effects of Catholic Schooling.” <em>Journal of Human Resources</em> 40 (4): 791–821.</p>
</div>
<div id="ref-durbin1954">
<p>Durbin, James. 1954. “Errors in Variables.” <em>Revue de L’institut International de Statistique</em>, 23–32.</p>
</div>
<div id="ref-hausman1978">
<p>Hausman, Jerry A. 1978. “Specification Tests in Econometrics.” <em>Econometrica: Journal of the Econometric Society</em>, 1251–71.</p>
</div>
<div id="ref-oster2019">
<p>Oster, Emily. 2019. “Unobservable Selection and Coefficient Stability: Theory and Evidence.” <em>Journal of Business &amp; Economic Statistics</em> 37 (2): 187–204. <a href="https://doi.org/10.1080/07350015.2016.1227711">https://doi.org/10.1080/07350015.2016.1227711</a>.</p>
</div>
<div id="ref-wu1973">
<p>Wu, De-Min. 1973. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances.” <em>Econometrica: Journal of the Econometric Society</em>, 733–50.</p>
</div>
<div id="ref-wu1974">
<p>———. 1974. “Alternative Tests of Independence Between Stochastic Regressors and Disturbances: Finite Sample Results.” <em>Econometrica: Journal of the Econometric Society</em>, 529–46.</p>
</div>
</div>
</div>
